{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ff2b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import polars as pl\n",
    "import torch\n",
    "from bitsandbytes.optim import PagedLion8bit\n",
    "from peft import LoraConfig, PeftModel, get_peft_model\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "from flashml import (\n",
    "    inspect_model,\n",
    ")\n",
    "from flashml.schedulers import LRConsineAnnealingWithLinearWarmup\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "\n",
    "HYPERPARAMS = {\n",
    "    \"model\": \"Qwen/Qwen3-0.6B\",  # \"tiiuae/Falcon-H1-0.5B-Base\",\n",
    "    \"continue_from_index\": -1,\n",
    "    \"seed\": 42,\n",
    "    \"batch_size\": 2,\n",
    "    \"gradient_accumulation\": 8,\n",
    "    \"cross_entropy_weight\": torch.tensor(\n",
    "        [0.0785904383236605, 0.9214095616763395], dtype=torch.float\n",
    "    ),\n",
    "    \"epochs\": 1,\n",
    "    \"lr\": 2e-5,\n",
    "    \"betas\": (0.9, 0.999),\n",
    "    \"weight_decay\": 0.005,\n",
    "    \"quant_config\": BitsAndBytesConfig(\n",
    "        # load_in_8bit=True,\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "    ),\n",
    "    \"lora_config\": LoraConfig(\n",
    "        r=32,  # 8\n",
    "        lora_alpha=32,  # 16\n",
    "        target_modules=[\n",
    "            \"q_proj\",\n",
    "            \"v_proj\",\n",
    "        ],\n",
    "        lora_dropout=0.05,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003ab4a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b69e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"answerdotai/ModernBERT-base\")\n",
    "\n",
    "from flashml import inspect_model\n",
    "\n",
    "inputs = tokenizer(\"Hello world!\", return_tensors=\"pt\")\n",
    "\n",
    "model = AutoModel.from_pretrained(\"answerdotai/ModernBERT-base\")\n",
    "import torch\n",
    "\n",
    "input_tuple = (\n",
    "    inputs[\"input_ids\"],\n",
    "    inputs[\"attention_mask\"],\n",
    "    inputs[\"token_type_ids\"] if \"token_type_ids\" in inputs else None,\n",
    ")\n",
    "\n",
    "# Inspect the model using positional inputs\n",
    "inspect_model(model, input_data=input_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dc9c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification import make_dummy_classification_dataset\n",
    "\n",
    "x = make_dummy_classification_dataset()\n",
    "x\n",
    "\n",
    "from classification import run_dummy_classifiers, run_linear_classifier\n",
    "\n",
    "run_dummy_classifiers(*x)\n",
    "\n",
    "run_linear_classifier(*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c116716",
   "metadata": {},
   "outputs": [],
   "source": [
    "from regression import make_dummy_regression_dataset\n",
    "\n",
    "x = make_dummy_regression_dataset()\n",
    "x\n",
    "\n",
    "from regression import run_dummy_regressors, run_linear_regressor\n",
    "\n",
    "run_dummy_regressors(*x)\n",
    "\n",
    "run_linear_regressor(*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f509c0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Larger dummy binary classification data\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "size = 100\n",
    "target = np.random.choice([0, 1], size=size, p=[0.6, 0.4])  # 60% zeros, 40% ones\n",
    "predicted = np.random.choice(\n",
    "    [0, 1], size=size, p=[0.5, 0.5]\n",
    ")  # Random predictions, balanced\n",
    "\n",
    "\n",
    "from classification import plot_confusion_matrix\n",
    "\n",
    "plot_confusion_matrix(predicted, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71d2537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from classification import (\n",
    "    compute_binary_classification_metrics,\n",
    "    compute_multiclass_classification_metrics,\n",
    ")\n",
    "\n",
    "# Binary example\n",
    "binary_scores = np.array([[0.9], [0.7], [0.4], [0.8]])\n",
    "binary_target = np.array([[0], [1], [0], [1]])\n",
    "binary_metrics = compute_binary_classification_metrics(\n",
    "    binary_scores, binary_target, threshold=0.5\n",
    ")\n",
    "\n",
    "# Multiclass example\n",
    "multi_scores = np.array([[0.1, 0.9], [0.6, 0.4], [0.3, 0.7]])\n",
    "multi_target = np.array([1, 0, 1])\n",
    "multi_metrics = compute_multiclass_classification_metrics(multi_scores, multi_target)\n",
    "\n",
    "\n",
    "from classification import find_best_threshold\n",
    "\n",
    "t = find_best_threshold(binary_scores, binary_target, bins=100)\n",
    "\n",
    "binary_metrics\n",
    "\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3650ac27",
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8829f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from classification import plot_roc_curve\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "# Create sample scores and targets\n",
    "target = np.random.binomial(1, 0.3, n_samples)\n",
    "scores = np.random.beta(2, 5, n_samples)\n",
    "scores[target == 1] += np.random.normal(0.3, 0.2, np.sum(target == 1))\n",
    "scores = np.clip(scores, 0, 1)\n",
    "# Plot ROC curve\n",
    "fig = plot_roc_curve(scores, target)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98c10fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from flashml.inspect import inspect_tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-4B\")\n",
    "inspect_tokenizer(tokenizer)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96427202",
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_tokenizer(tokenizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2409cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import random\n",
    "from flashml import log_metrics\n",
    "HYPERPARAMS = {\n",
    "    \"model\": \"Qwen/Qwen3-0.6B\",\n",
    "    \"continue_from_index\": -1,\n",
    "    \"seed\": 42,\n",
    "    \"batch_size\": 2,\n",
    "    \"gradient_accumulation\": 8,\n",
    "    \"epochs\": 1,\n",
    "    \"lr\": 2e-5,\n",
    "    \"betas\": (0.9, 0.999),\n",
    "    \"weight_decay\": 0.005,\n",
    "}\n",
    "loss = 10.0\n",
    "epochs = 3\n",
    "batches = 300\n",
    "for it in range(1):\n",
    "    for epoch in range(batches * epochs):\n",
    "        loss_ = math.log2(abs(loss))\n",
    "        acc = loss + random.random()\n",
    "        log_metrics(\n",
    "            {\"loss\": loss_, \"acc\": acc},\n",
    "            # step=(epoch, batches * epochs),\n",
    "            # experiment_name=None,\n",
    "        )\n",
    "        loss -= 1e-2\n",
    "        time.sleep(0.0002)\n",
    "    print(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd1b41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "from flashml.nlp import extract_text_within_tags\n",
    "# Test DataFrame for Pandas\n",
    "data_pandas = {\n",
    "    'text_column': [\n",
    "        '<tag>Hello World</tag>',\n",
    "        'No tags here',\n",
    "        '<tag>Another test</tag> with <tag>multiple tags</tag>',\n",
    "        '<tag></tag>',\n",
    "        'Random <other>text</other>'\n",
    "    ]\n",
    "}\n",
    "df_pandas = pd.DataFrame(data_pandas)\n",
    "# Apply function to Pandas DataFrame\n",
    "result_pandas = extract_text_within_tags(df_pandas, 'text_column', 'tag')\n",
    "print(\"Pandas Result:\")\n",
    "print(result_pandas)\n",
    "# Test DataFrame for Polars\n",
    "data_polars = pl.DataFrame({\n",
    "    'text_column': [\n",
    "        '<tag>Hello World</tag>',\n",
    "        'No tags here',\n",
    "        '<tag>Another test</tag> with <tag>multiple tags</tag>',\n",
    "        '<tag></tag>',\n",
    "        'Random <other>text</other>'\n",
    "    ]\n",
    "})\n",
    "# Apply function to Polars DataFrame\n",
    "result_polars = extract_text_within_tags(data_polars, 'text_column', 'tag')\n",
    "print(\"\\nPolars Result:\")\n",
    "print(result_polars)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
